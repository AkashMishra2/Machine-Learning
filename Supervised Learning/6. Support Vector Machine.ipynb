{
 "cells": [
  {
   "cell_type": "raw",
   "id": "8bec7d63-8bcc-4c12-8119-c0ee6bf38f69",
   "metadata": {},
   "source": [
    "Support vector machine (SVM)\n",
    "\n",
    "SVM solves problem of Regression and Classification. \n",
    "\n",
    "SVM it is a Powerful technique of Supervised Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b6c619-edd8-4a16-a8be-3b97fa4a9cc7",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26720462-802b-4d05-9a64-f21877f78af9",
   "metadata": {},
   "source": [
    "labeled data -> 1. male   2. female\n",
    "\n",
    "Step 1  Model training\n",
    "            |\n",
    "            V\n",
    "Step 2  Prediction   <--- New Data\n",
    "            |\n",
    "            V\n",
    "step 3    Output\n",
    "\n",
    "1. Formula for calculating distance \n",
    "\n",
    "    r = (w^T.x + b)/||w||\n",
    "\n",
    "2. Linear Support Vector Mathematical Equation\n",
    "    f(x) = sin(w^T.x + w)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9719f364-63de-4a3f-a4c6-cb1bf24eeb18",
   "metadata": {},
   "source": [
    "if I give the picture of a girl as new data I need Output as female class."
   ]
  },
  {
   "cell_type": "raw",
   "id": "9d154100-498e-42b1-9448-136f1579ecad",
   "metadata": {},
   "source": [
    "Take a training data. suppose that data contains info about gender.\n",
    "\n",
    "In SVM we create group for genders (male or female) seprate from each other and consider that we have draw a boundary line between(male and female).  boundary line(hyperplane)\n",
    "\n",
    "And that boundary line is decision line or hyperplane.\n",
    "\n",
    "Find the datapoints closest to the boundary line.\n",
    "\n",
    "Draw another line closest datapoint. That creates the sandwitch of boundary line. (line || boundary line)\n",
    "\n",
    "Now we get the distance of boundary line to line(female side) denoted as D1. &\n",
    "distance of boundary line to line(male side) denoted as D2.\n",
    "\n",
    "Margin = D1+D2. Margin must be maximum among all margins.\n",
    "\n",
    "Margin will dicide that which hyperplans will exist or not. because their are not only 1 hyperplane but their are\n",
    "multiple hyperplanes.\n",
    "\n",
    "NOTE : Those closest points are the support vectors.\n",
    "\n",
    "Margin : \n",
    "        When we draw multiple hyperplane we consider only one hyperplane depends upon the margin.\n",
    "The value of selected margin must have maximum value among all margins.\n",
    "Maximum margin width will best for the future prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1be09e88-304c-4af0-8454-9e42910c0834",
   "metadata": {},
   "source": [
    "1. Linear Support Vector Machine\n",
    "\n",
    "Linear Seprable data\n",
    "By drawing a line we seprate two data class(male and female) that is Linear Separable data. \n",
    "\n",
    "2. Non Linear Support Vector Machine (Soft Margin Classification)\n",
    "\n",
    "When datapoints of two calsses such as (male and female) are mixed . We cann't separate data classes by drawing line.\n",
    "accuracy of model will decrease.\n",
    "\n",
    "By drawing a line we cann't seprate two data class(male and female) that is Non-Linear Separable data.\n",
    "We use Non-Linear SVM.\n",
    "\n",
    "\n",
    "\n",
    "In situation of Non Linear Support Vector Machine we add \"slack variable\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b1223c51-2491-4209-9dea-5c74f8250c83",
   "metadata": {},
   "source": [
    " Non Linear Support Vector Machine\n",
    "\n",
    "When datapoints of two calsses such as (male and female) are mixed . We cann't separate data classes by drawing line.\n",
    "accuracy of model will decrease.\n",
    "\n",
    "By drawing a line we cann't seprate two data class(male and female) that is Non-Linear Separable data.\n",
    "We use Non-Linear SVM.\n",
    "\n",
    "To handle such problem we use kernel function\n",
    "\n",
    "kernel function\n",
    "                takes input -> Low Dimensional Feature Space (data in form of non seperable space) \n",
    "                                            |\n",
    "                                            V\n",
    "                                    kernel function\n",
    "                                            |\n",
    "                                            V\n",
    "                returns output -> High Dimensional Feature Space\n",
    "\n",
    "2-D feature space -> Sepreated by line\n",
    "3-D feature space -> Sepreated by plane\n",
    "\n",
    "kernel function convert data low dimensional Feature space  into  High Dimensional Feature Scale.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9022148c-79ab-46a0-96ab-15828088d0d4",
   "metadata": {},
   "source": [
    "Popular kernel function\n",
    "\n",
    "1. Linear kernel : K(xi,xj) = xi.xj\n",
    "2. Polynomial kernel with degree 'd' : K(xi,xj) = (1+ xi.xj)^d  d=2,3,4,....,n\n",
    "3. Gaussian(Radia Basis Function) kernel with width 'sigma'): K(xi,xj) = e^-(||xi-xj||^2/2(sigma)^2)\n",
    "                                                              K(xi,xj) = e^-Gamma(||xi-xj||^2)   Gamma = 1/2(sigma)^2\n",
    "\n",
    "4. Sigmoid with parameter k and c : K(Xi,Xj) = tanh(kxi.xj+c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
